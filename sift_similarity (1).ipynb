{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sift_similarity.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rba2Icjhwy4U",
        "outputId": "5a34f3ba-36ec-4ba7-91bd-a836659018b5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1RxAs8XxFkM",
        "outputId": "12dd2a0a-32b6-4923-81ad-6cd6bb93b586"
      },
      "source": [
        "!pip install -U scipy==1.2.0\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scipy==1.2.0\n",
            "  Downloading scipy-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (26.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.6 MB 53.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.2.0) (1.19.5)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jax 0.2.25 requires scipy>=1.2.1, but you have scipy 1.2.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scipy-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install skimage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0Z8Y8oamwqj",
        "outputId": "45b24fd2-5da0-46b5-ea0f-70d402de0365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting skimage\n",
            "  Downloading skimage-0.0.tar.gz (757 bytes)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/3b/ee/edbfa69ba7b7d9726e634bfbeefd04b5a1764e9e74867ec916113eeaf4a1/skimage-0.0.tar.gz#sha256=6c96a11d9deea68489c9b80b38fad1dcdab582c36d4fa093b99b24a3b30c38ec (from https://pypi.org/simple/skimage/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement skimage (from versions: 0.0)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for skimage\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0K4dToawP2I",
        "outputId": "3da17235-ab26-4e39-f274-816404d89c9f"
      },
      "source": [
        "import warnings\n",
        "from skimage import measure\n",
        "#from skimage.measure import compare_ssim\n",
        "from skimage import measure\n",
        "from skimage.transform import resize\n",
        "from scipy.stats import wasserstein_distance\n",
        "from scipy.misc import imsave\n",
        "from scipy.ndimage import imread\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "##\n",
        "# Globals\n",
        "##\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# specify resized image sizes\n",
        "height = 2**10\n",
        "width = 2**10\n",
        "\n",
        "def get_img(path, norm_size=True, norm_exposure=False):\n",
        "  '''\n",
        "  Prepare an image for image processing tasks\n",
        "  '''\n",
        "  # flatten returns a 2d grayscale array\n",
        "  img = imread(path, flatten=True).astype(int)\n",
        "  # resizing returns float vals 0:255; convert to ints for downstream tasks\n",
        "  if norm_size:\n",
        "    img = resize(img, (height, width), anti_aliasing=True, preserve_range=True)\n",
        "  if norm_exposure:\n",
        "    img = normalize_exposure(img)\n",
        "  return img\n",
        "\n",
        "\n",
        "def get_histogram(img):\n",
        "  '''\n",
        "  Get the histogram of an image. For an 8-bit, grayscale image, the\n",
        "  histogram will be a 256 unit vector in which the nth value indicates\n",
        "  the percent of the pixels in the image with the given darkness level.\n",
        "  The histogram's values sum to 1.\n",
        "  '''\n",
        "  h, w = img.shape\n",
        "  hist = [0.0] * 256\n",
        "  for i in range(h):\n",
        "    for j in range(w):\n",
        "      hist[img[i, j]] += 1\n",
        "  return np.array(hist) / (h * w) \n",
        "\n",
        "\n",
        "def normalize_exposure(img):\n",
        "  '''\n",
        "  Normalize the exposure of an image.\n",
        "  '''\n",
        "  img = img.astype(int)\n",
        "  hist = get_histogram(img)\n",
        "  # get the sum of vals accumulated by each position in hist\n",
        "  cdf = np.array([sum(hist[:i+1]) for i in range(len(hist))])\n",
        "  # determine the normalization values for each unit of the cdf\n",
        "  sk = np.uint8(255 * cdf)\n",
        "  # normalize each position in the output image\n",
        "  height, width = img.shape\n",
        "  normalized = np.zeros_like(img)\n",
        "  for i in range(0, height):\n",
        "    for j in range(0, width):\n",
        "      normalized[i, j] = sk[img[i, j]]\n",
        "  return normalized.astype(int)\n",
        "\n",
        "\n",
        "def earth_movers_distance(path_a, path_b):\n",
        "  '''\n",
        "  Measure the Earth Mover's distance between two images\n",
        "  @args:\n",
        "    {str} path_a: the path to an image file\n",
        "    {str} path_b: the path to an image file\n",
        "  @returns:\n",
        "    TODO\n",
        "  '''\n",
        "  img_a = get_img(path_a, norm_exposure=True)\n",
        "  img_b = get_img(path_b, norm_exposure=True)\n",
        "  hist_a = get_histogram(img_a)\n",
        "  hist_b = get_histogram(img_b)\n",
        "  return wasserstein_distance(hist_a, hist_b)\n",
        "\n",
        "\n",
        "\n",
        "def pixel_sim(path_a, path_b):\n",
        "  '''\n",
        "  Measure the pixel-level similarity between two images\n",
        "  @args:\n",
        "    {str} path_a: the path to an image file\n",
        "    {str} path_b: the path to an image file\n",
        "  @returns:\n",
        "    {float} a float {-1:1} that measures structural similarity\n",
        "      between the input images\n",
        "  '''\n",
        "  img_a = get_img(path_a, norm_exposure=True)\n",
        "  img_b = get_img(path_b, norm_exposure=True)\n",
        "  return np.sum(np.absolute(img_a - img_b)) / (height*width) / 255\n",
        "\n",
        "\n",
        "def sift_sim(path_a, path_b):\n",
        "  '''\n",
        "  Use SIFT features to measure image similarity\n",
        "  @args:\n",
        "    {str} path_a: the path to an image file\n",
        "    {str} path_b: the path to an image file\n",
        "  @returns:\n",
        "    TODO\n",
        "  '''\n",
        "  # initialize the sift feature detector\n",
        "  orb = cv2.ORB_create()\n",
        "\n",
        "  # get the images\n",
        "  img_a = cv2.imread(path_a)\n",
        "  img_b = cv2.imread(path_b)\n",
        "\n",
        "  # find the keypoints and descriptors with SIFT\n",
        "  kp_a, desc_a = orb.detectAndCompute(img_a, None)\n",
        "  kp_b, desc_b = orb.detectAndCompute(img_b, None)\n",
        "\n",
        "  # initialize the bruteforce matcher\n",
        "  bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "\n",
        "  # match.distance is a float between {0:100} - lower means more similar\n",
        "  matches = bf.match(desc_a, desc_b)\n",
        "  similar_regions = [i for i in matches if i.distance < 70]\n",
        "  if len(matches) == 0:\n",
        "    return 0\n",
        "  return len(similar_regions) / len(matches)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  img_a = '/content/drive/MyDrive/Melanoma/r4.jpg'\n",
        "  img_b = '/content/drive/MyDrive/Melanoma/r5.jpg'\n",
        "  \n",
        "  \n",
        "  # get the similarity values\n",
        "  \n",
        "  pixel_sim = pixel_sim(img_a, img_b)\n",
        "  sift_sim = sift_sim(img_a, img_b)\n",
        "  emd = earth_movers_distance(img_a, img_b)\n",
        "  print(pixel_sim, sift_sim, emd)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3250648722929113 0.8571428571428571 0.00029715895652770996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zFcYMOydpIfP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}